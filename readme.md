**installing dependesises**
# Dans le  projet afin d'installer toute les dependance n'essaire 
 dans le fichier  requirement.txt se trouve toute les dependance a installer executer la commande suivante 

pip install -r requirements.txt

pour l'instalation du model voici un lien vert l'instalation du SetUp Llaulma 
https://ollama.com/library/llama3.2:1b

# instruction du choix du model

apres instalation de Setup Ollama choisissez : 

le model Gamma 3:1B   (exelent choix et léger et vif) l'esser le se telecharger et tester en envoyant des petit ptompte si sa marche 


execute the code llm_service.py just to see if the LLM is responding 


# Next step

we code alll files that u see here all the API gonna do the work 

(vous pouvez choisir un model plus gourment a condition que vous avez un GPU puissant intéguré)